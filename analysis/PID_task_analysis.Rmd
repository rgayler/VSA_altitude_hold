---
title: "PID Task Analysis"
author: "Ross Gayler"
date: "2021-08-20"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

suppressPackageStartupMessages(
  {
    library(fs)
    library(here)
    library(vroom)
    library(dplyr)
    library(stringr)
    library(ggplot2)
    library(mgcv)
  }
)

source(here::here("R", "functions.R"))
```

This notebook attempts to statistically characterise the PID controller
as a black-box function.

Looking at the [data flow diagram for Design
01](design_notes.html#dfd-01), and ignoring the tuning parameters, there
are three input variables:

-   Altitude ($z$)
-   Vertical velocity ($dz$)
-   Target altitude ($k_{tgt}$)

And one output variable:

-   Clipped motor demand ($i8 \triangleq u$)

The integrated error nodes ($i4$, $i5$, $i9$) introduce a history
dependence into the PID function. This part of the DFD implements the
"I" (integral) term of "PID" controller. However, the previous analyses
of the simulation data suggest that the integral term is only effective
in the final phase of the approach to the target altitude, and
introduces an (at best) harmless oscillation. This suggests that the I
term may be unnecessary in this application.

If the I (integrated error) term is dropped from the PID controller it
becomes a purely feed-forward, stateless function, which would be very
easy to implement.

The purpose of this notebook is to statistically characterise the PID
controller function as a stateless, feed-forward function. This function
could be compared to the simulated data to see what has been lost by
dropping the I term.

It is worth emphasizing that the PID controller being modelled is
completely fixed (i.e.it does not learn the control function and is not
adaptive to any changes) and is not guaranteed to be optimally tuned.

# Read data

This notebook is based on the data generated by the simulation runs with
multiple target altitudes per run.

Read the data from the simulations and mathematically reconstruct the
values of the nodes not included in the input files.

```{r}
# function to clip value to a range
clip <- function(
  x, # numeric
  x_min, # numeric[1] - minimum output value
  x_max  # numeric[1] - maximum output value
) # value # numeric - x constrained to the range [x_min, x_max]
  {
  x %>% pmax(x_min) %>% pmin(x_max)
}

# function to extract a numeric parameter value from the file name
get_param_num <- function(
  file, # character - vector of file names
  regexp # character[1] - regular expression for "param=value"
         # use a capture group to get the value part
) # value # numeric - vector of parameter values
{
  file %>% str_match(regexp) %>% 
      subset(select = 2) %>% as.numeric()
}

# function to extract a sequence of numeric parameter values from the file name
get_param_num_seq <- function(
  file, # character - vector of file names
  regexp # character[1] - regular expression for "param=value"
         # use a capture group to get the value part
) # value # character - character representation of a sequence, e.g. "(1,2,3)"
{
  file %>% str_match(regexp) %>% 
      subset(select = 2) %>% 
    str_replace_all(c("^" = "(", "_" = ",", "$" = ")")) # reformat as sequence
}

# function to extract a logical parameter value from the file name
get_param_log <- function(
  file, # character - vector of file names
  regexp # character[1] - regular expression for "param=value"
  # use a capture group to get the value part
  # value *must* be T or F
) # value # logical - vector of logical parameter values
{
  file %>% str_match(regexp) %>% 
    subset(select = 2) %>% as.character() %>% "=="("T")
}

# read the data
d_wide <- fs::dir_ls(path = here::here("data", "multiple_target"), regexp = "/targets=.*\\.csv$") %>% # get file paths
  vroom::vroom(id = "file") %>% # read files
  dplyr::rename(k_tgt = target) %>% # rename for consistency with single target data
  dplyr::mutate( # add extra columns
    file = file %>% fs::path_ext_remove() %>% fs::path_file(), # get file name
    # get parameters
    targets  = file %>% get_param_num_seq("targets=([._0-9]+)_start="), # hacky
    k_start  = file %>% get_param_num("start=([.0-9]+)"), 
    sim_id   = paste(targets, k_start), # short ID for each simulation
    k_p      = file %>% get_param_num("kp=([.0-9]+)"),
    k_i      = file %>% get_param_num("Ki=([.0-9]+)"),
    # k_tgt    = file %>% get_param_num("k_tgt=([.0-9]+)"), # no longer needed
    k_windup = file %>% get_param_num("k_windup=([.0-9]+)"),
    uclip    = FALSE, # constant across all files
    dz0      = TRUE, # constant across all files
    # Deal with the fact that the interpretation of the imported u value
    # depends on the uclip parameter
    u_import = u, # keep a copy of the imported value to one side
    u = dplyr::if_else(uclip, # make u the "correct" value
                       u_import, 
                       clip(u_import, 0, 1)
                       ),
    # reconstruct the missing nodes
    i1 = k_tgt - z,
    i2 = i1 - dz,
    i3 = e * k_p,
    i9 = lag(ei, n = 1, default = 0), # initialised to zero
    i4 = e + i9,
    i5 = i4 %>% clip(-k_windup, k_windup),
    i6 = ei * k_i,
    i7 = i3 + i6,
    i8 = i7 %>% clip(0, 1)
  ) %>% 
  # add time variable per file
  dplyr::group_by(file) %>% 
  dplyr::mutate(t = 1:n()) %>% 
  dplyr::ungroup()

dplyr::glimpse(d_wide)
```

# Plot the data

The altitude error ($i1$) is a deterministic function of the altitude
($z$) and the altitude target ($k_{tgt}$). The two inputs $z$ and
$k_{tgt}$ can be replaced with the single input $i1$. This has the
advantage of meaning that there are only two inputs $i1$, and $dz$,
which can be represented on a plane.

Display the distribution of input values to the PID controller across
all simulation runs.

```{r}
d_wide %>% 
  ggplot(aes(x = i1, y = dz)) +
  geom_abline(slope = 1, intercept = 0, colour = "red") + # reference line
  geom_point(alpha = 0.1) +
  coord_equal()
```

-   The dark (because there are many overlapping points) diagonal line
    corresponds to the final phase of all the trajectories where the
    altitude error and vertical velocity both decrease to zero with any
    approximately constant ratio between the two quantities.

    -   The ratio is 1:1. That is, the line corresponds to
        $i2 (\triangleq i1n- dz) = 0$.
    -   The central diagonal line deviates from $i2 = 0$ for
        $dz \lt -2.5$. This appears to be due to slight overshoot of the
        initial trajectories leading into the diagonal.

-   The light, approximately vertical curves correspond to the initial
    phase of all the trajectories, where the multicopter is either
    climbing at full power or dropping at zero power.

Rotate the axes by 45 degrees to make the diagonal axis-parallel in the
new coordinates.

```{r}
d_wide %>% 
  ggplot(aes( x = i1 - dz, y = (i1 + dz)/2)) +
  geom_point(alpha = 0.1) +
  coord_equal()
```

-   The x axis is equivalent to $i2$.

Add the clipped motor command to the plot.

The clipped motor command lies in the range $[0, 1]$ and 0.524 is the
command level for hovering. It will be useful to rescale the motor
command level so that zero corresponds to hover and the magnitude of the
maximum deviation from hover is one.

```{r}
p <- d_wide %>% 
  dplyr::mutate(i8_scl = (i8 - 0.524) / 0.524) %>% 
  ggplot(aes(group = paste(sim_id, k_tgt))) +
  scale_color_viridis_c()

p +
  geom_point(aes(x = i1 - dz, y = (i1 + dz)/2, 
                 size = abs(i8_scl), colour = i8_scl),
             alpha = 0.5) +
  geom_path(aes(x = i1 - dz, y = (i1 + dz)/2), alpha = 0.2)
```

Remember, $e \triangleq i2 \triangleq i1 - dz$. $e$ is the "error",
which should be interpreted as the predicted altitude error in one
second, assuming that the multicopter maintains the current vertical
velocity.

This graph is a plan view, looking down on the surface to be modelled as
a function of the input variables.

-   When $e \lt 0$ (the left half-plane), the motor command $i8$ is
    minimum.
-   When $e \gt 0$ (the right half-plane), the motor command $i8$ is
    (approximately) maximum.
-   When $e \approx 0$ (the final phase of the trajectories) the motor
    command decreases as the $y$ axis increases.

```{r}
p +
  geom_point(aes(x = i1 - dz, y = i8_scl, 
                 size = abs(i8_scl), colour = i8_scl), 
             alpha = 0.5) +
  geom_path(aes(x = i1 - dz, y = i8_scl), alpha = 0.2)
```

This graph is a side view of the surface to be modelled. The $x$ axis
corresponds to $e$ and the orthogonal input ($(i1 + dz)/2)$) is
collapsed over.

To a first approximation:

-   When $e \lt 0$ (the left half-plane), the motor command $i8$ is
    minimum.

-   When $e \gt 0$ (the right half-plane), the motor command $i8$ is
    (approximately) maximum.

    -   The aproximation here is that as $e$ approaches zero from above,
        when it gets sufficiently close to zero the motor command scales
        down from the maximum.

```{r}
p +
  geom_abline(slope = -1/20, intercept = 0, colour = "red") + # reference line
  geom_point(aes(x = (i1 + dz)/2, y = i8_scl, 
                 size = abs(i8_scl), colour = i8_scl), 
             alpha = 0.5) +
  geom_path(aes(x = (i1 + dz)/2, y = i8_scl), alpha = 0.2)

```

This graph is the other side view of the surface to be modelled. The $x$
axis corresponds to ($(i1 + dz)/2)$) and the orthogonal input $e$ is
collapsed over.

-   Ignoring the overshoots and oscillations, when the trajectories are
    in the final phase ($e \approx 0$), the motor command is a linear
    function of $(i1 + dz)/2$.
-   The trajectories "drop" suddenly from the initial phase to the final
    phase.

## Summary

-   Ignoring the overshoots and oscillations the overall shape of the
    function surface is not very complex (e.g. it's not fractal).
-   The surface does involve an interaction. (It can't be modelled as
    the sum of axis-parallel effects.)
-   There are sharp discontinuities.
-   The data from the initial phases is rather sparsely distributed over
    the input plane. This means that "learning" the function will
    require some strong biases to paper over the gaps.

# Model the data

Fitting a smoothing spline regression to the data, it is very helpful if
the predictor variables capture the major features of the data (to
minimise the work done by the smoothing). Using an appropriately crafted
set of predictor variables provides a bias to the functions that can be
learned from the data.

I will use [Generalised Additive Models
(GAM)](https://en.wikipedia.org/wiki/Generalized_additive_model) as the
modelling technique here.

## Without feature engineering

Show what a GAM can do without any problem-specific feature engineering.

Fit marginal smooths first to help build up intuition.

### $e$ term

Remember that $u \triangleq i8$.

Model $u$ as a function of $e$.

```{r}
fit1 <- mgcv::gam(u ~ s(e, bs =  "ad"), data = d_wide)
summary(fit1)
plot(fit1)
```

This uses an adaptive smoother (`bs = "ad"`) so that the degrees of
freedom are concentrated where the curvature is highest.

The scaling on the $y$ axis of the plot is arbitrary.

-   The smooth picks up the strong dependency of motor command $u$ on
    the sign of the error $e$.
-   \~86% deviance explained. (Most of the variance of the motor command
    is explained by the $e$ term.)

### $e_{orth}$ term

I will use $e_{orth}$ as a convenience to refer to $(i1 + dz)/2$ because
it is orthogonal to $e$.

Model $u$ as a function of $e_{orth}$.

```{r}
fit2 <- mgcv::gam(u ~ s(I((i1 + dz)/2), bs =  "ad"), data = d_wide)
summary(fit2)
plot(fit2)
```

-   The central, slightly negatively sloped section from -2 to +2
    captures the relation ship to $u$ in the terminal phases of the
    trajectories ($e \approx 0$).
-   Outside that range, most of the observations are in the initial
    phases of the trajectories, so tend to be at extreme values of $u$.
-   \~16% deviance explained. ($e_{orth}$ only explains a small fraction
    of of the variance of the motor command, and even this might be
    dominated by the points outside the terminal phases of the
    trajectories.)

Fit the model on a subset of the observations corresponding to the
terminal phases.

```{r}
fit3 <- mgcv::gam(u ~ s(I((i1 + dz)/2), bs =  "cr"), data = d_wide, 
                  subset = abs(e) < 0.1)
plot(fit3)
```

-   The negative slope in the terminal phases is clear. (The
    nonmonotonicity at the left end is due to a small number of outlier
    points).

### Joint smooth

Fit a smooth that is a function of the joint values of $e$ and
$e_{orth}$.

Use a thin-plate smoothing basis (`bs = "tp"`).

```{r}
fit4 <- mgcv::gam(u ~ s(e, I((i1 + dz)/2), bs =  "tp"), data = d_wide)
summary(fit4)
plot(fit4, se = FALSE, scheme = 2)
plot(fit4, se = FALSE, scheme = 1, theta = -30)
```

-   The smooth captures the strong dependency between $u$ and $e$.
-   The smooth fails to capture the relationship with $e_{orth}$ at
    $e \approx 0$.
-   \~88% deviance explained. (This is only a slight increase relative
    to modelling only the $e$ term.)

## With feature engineering

Model the function, this time using features designed to capture the
major aspects of the shape of the surface. Such features constitute a
strong bias on the set of functions that can be learned from the data.
They also provide a mechanism for extrapolating outside the support of
the data.

### $e$ terms

The previous analyses showed that the surface should be partitioned into
three regions along $e$.

-   When $e < 0$ then $u$ is constant at 0 (initial phase of
    trajectories).
-   When $e > 0$ then $u$ is roughly constant at (initial phase of
    trajectories).
-   When $e = 0$ then $u$ is roughly a linear function of $e_{orth}$
    (terminal phase of trajectories).

The $e = 0$ class is infinitesimally narrow, which is likely to cause
problems in a practical system. Consequently, I will make that class a
small finite width.

```{r}
e_fuzz <- 0.1 # half width of central strip
fit5 <- mgcv::gam(u ~ I(e >= e_fuzz) + I(abs(e) < e_fuzz), data = d_wide)
summary(fit5)
```

Scoring out regions by eye from the regression coefficients (this is a
step function):

-   $e \le -0.1$ - $u \approx 0$

-   $-0.1 \lt e \lt +0.1$ - $u \approx 0.52$

-   $e \ge +0.1$ - $u \approx 0.74$

-   \~78% deviance explained (compared to 86% for the smoothing spline
    model).

Look at the plot of `fit1`. The smoothing spline model has a slope
between \$e \approx 04 and $e \approx 2$. The current model (`fit5`)
can't account for this slope, which is why the goodness of fit is
reduced.

However, it's not clear that the slope is actually needed for the
controller to work well, so I'll ignore it.

### $e_{orth}$ term

Now add the $e_{orth}$ into the model.

$u$ is a linear function of $e_{orth}$ when $e \approx 0$ and irrelevant
elsewhere, which requires an interaction of $e_{orth}$ with $e$.

```{r}
fit6 <- mgcv::gam(
  u ~ I(e >= e_fuzz) + I(abs(e) < e_fuzz) +
    I(as.numeric(abs(e) < e_fuzz) * (i1 + dz)/2), 
  data = d_wide)
summary(fit6)
```

Scoring out regions by eye from the regression coefficients (this is a
step function):

-   $e \le -0.1$ - $u \approx 0$

-   $-0.1 \lt e \lt +0.1$ - $u \approx -0.027 e_{orth} + 0.52$

-   $e \ge +0.1$ - $u \approx 0.74$

-   \~83% deviance explained (compared to 88% for the bivariate
    smoothing spline model).

This model seems to pick up the major features of the surface.

In a future analysis I will use the construction of these terms to guide
the placement of the knots in VSA representations of scalars.
