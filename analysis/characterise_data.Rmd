---
title: "Characterise Simulation Data"
author: "Ross Gayler"
date: "2021-06-22"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

suppressPackageStartupMessages(
  {
    library(fs)
    library(here)
    library(vroom)
    library(dplyr)
    library(DT)
    library(stringr)
    library(skimr)
    library(forcats)
    library(ggplot2)
  }
)

source(here::here("R", "functions.R"))
```

This notebook characterises data generated by the simulation of the
classically implemented altitude hold controller. We need to understand
the properties of the signals in order to design VSA implementations of
them.

The values to be characterised are all the real scalars corresponding to
the nodes in the [data flow diagram for Design
01](design_notes.html#dfd-01).

# Data

The data is generated from runs of the classically implemented
simulation.

The data files are stored in the `data` directory.

The data is supplied as CSV files, each file corresponding to a
different run of the simulation.

Each run of the simulation corresponds to a set of starting conditions
and parameters.

The only starting condition that varies between runs is the initial
altitude. In effect, the multicopter is dropped from some height, with
the motors stopped and the drone must command the motors to attain the
target altitude.

The name of each data file contains the values of all the parameters. In
this work the target altitude is always constant at 5 metres, but more
generally this should be treated as a demand which can vary with time.

Each row of the data file corresponds to a point in time and successive
rows correspond to successive points in time. (This is a discrete time
simulation with fixed time steps.)

Each file contains 500 time steps.

Each columns of the data file corresponds to a node of the data flow
diagram.

Only a subset of the nodes are supplied (the nodes in rectangular boxes
in the DFD supplied by Simon Levy) and the values of the other nodes can
be reconstructed mathematically.

The values supplied from the input files are recorded to three decimal
places, so there is scope for approximation error due to the limited
precision.

Where a node value is supplied from the input file use that value and
can also be mathematically reconstructed from upstream values, us the
input value (rather than the reconstructed value) as input to downstream
calculations. This is to avoid propagating approximation errors.

## Read data

Read the data from the simulations and mathematically reconstruct the
values of the nodes not included in the input files.

```{r echo = TRUE}
# function to clip value to a range
clip <- function(
  x, # numeric
  x_min, # numeric[1] - minimum output value
  x_max  # numeric[1] - maximum output value
) # value # numeric - x constrrained to the range [x_min, x_max]
  {
  x %>% pmax(x_min) %>% pmin(x_max)
}

# function to extract a parametr value from the file name
get_param <- function(
  file, # character - vector of file names
  regexp # character[1] - regular expression for "param=value"
         # use a capture group to get the value part
) # value # numeric - vector of parameter values
{
  file %>% str_match(regexp) %>% 
      subset(select = 2) %>% as.numeric()
}

# read the data
d_wide <- fs::dir_ls(path = here::here("data"), regexp = "/k_start=.*\\.csv$") %>% # get file paths
  vroom::vroom(id = "file") %>% # read files
  dplyr::mutate( # add extra columns
    file = file %>% fs::path_ext_remove() %>% fs::path_file(), # get file name
    # get parameters
    k_start  = file %>% get_param("k_start=([.0-9]+)"), 
    k_p      = file %>% get_param("kp=([.0-9]+)"),
    k_i      = file %>% get_param("Ki=([.0-9]+)"),
    k_tgt    = file %>% get_param("k_tgt=([.0-9]+)"),
    k_windup = file %>% get_param("k_windup=([.0-9]+)"),
    # reconstruct the missing nodes
    i1 = k_tgt - z,
    i2 = i1 - dz,
    i3 = e * k_p,
    i9 = lag(ei, n = 1, default = 0),
    i4 = e + i9,
    i5 = i4 %>% clip(-k_windup, k_windup),
    i6 = ei * k_i,
    i7 = i3 + i6,
    i8 = i7 %>% clip(0, 1)
  ) %>% 
  # add time variable per file
  dplyr::group_by(file) %>% 
  dplyr::mutate(t = 1:n()) %>% 
  dplyr::ungroup()

dplyr::glimpse(d_wide)
```

## Check data

Check the data for consistency.

### Initial values

The different starting conditions correspond to the multicopter being
dropped/released at different altitudes. At the moment of release the
multicopter should be at exactly the starting altitude and have zero
vertical velocity. Check that this is true.

```{r}
d_wide %>% 
  dplyr::group_by(file) %>% 
  dplyr::slice_head(n = 1) %>% 
  dplyr::ungroup() %>% 
  dplyr::arrange(k_start) %>% 
  dplyr::select(k_start, z, dz) %>% 
  DT::datatable(rownames = FALSE)
```

-   The initial vertical velocities ($dz$) are nonzero. The most likely
    interpretation is that the $z$ and $dz$ values are skewed by one
    time step. An alternative interpretation is that the multicopter was
    released one time step earlier and a little higher than the target
    altitude so that it passes through the target altitude exactly one
    time step after release.

This apparent skew probably doesn't make any substantial difference to
the qualitative performance of the system. However, it makes some of the
graphs messier because the trajectory doesn't start at zero. It *may*
also lead to the altitude converging slightly off the target altitude
because the "perceived" altitude is not quite time-aligned with the
error signal.

### Check $z$ and $dz$

The altitude ($z$) and vertical velocity ($dz$) are input values fro the
simulation data files. Given only a single point in time, they are
independent variables. However, we are given a time series of values and
the vertical velocity should be a function of the time series of
altitude.

Given that the multicopter simulation is a discrete time simulation, the
most likely interpretation is that $dz$ is calculated as the difference
between successive $z$ values. Check whether that is the case.

```{r}
d_wide %>% 
  dplyr::group_by(file) %>% 
  dplyr::mutate(
    dz_est = z - lag(z, n = 1, default = NA),
  ) %>% 
  ggplot() +
  geom_point(aes(x = dz_est, y = dz))
```

-   The supplied $dz$ is a linear transform of estimated vertical
    velocity (difference between successive altitude values).

    -   I am prepared to believe that the inacurracy is due to the low
        precision of the values in the files.

-   But, the scaling is **very** different: $dz = 100 dz_{est}$. The
    time step is 10 ms, so it looks like like $dz$ is in units of metres
    per second and $dz_{est}$ is in units of metres per time step.

Looking at the PID calculation of error ($e$): $$
\begin{aligned}
  e &= k_{tgt} - z - dz \\
    &= k_{tgt} - (z + dz)
\end{aligned}
$$\
The term $(z + dz)$ is effectively a prediction of the altitude at the
next time step based on the altitude $z$ and vertical velocity $dz$ at
the previous time step. Thus, the error $e$ is the difference between
the target altitude and the predicted altitude. This requires $z$ and
$dz$ to be measured in compatible units for the prediction $(z + dz)$ to
make sense. Both quantities must be measured in metres and $dz$ must be
metres over the relevant time period, which is one time step.

Consequently, I believe $dz$ is scaled wrongly because the prediction
$(z + dz)$ is the prediction for a point 100 time steps in the future.

### Check calculated values

Where possible compare the calculated values with the values recorded
from the simulator.

Nodes with a single input edge can be checked against the output of the
predecessor node.

The nodes which can be checked are: *e*, *ei*, *u*

```{r}
# e = i2
summary(d_wide$e - d_wide$i2)

# ei = i5
summary(d_wide$ei - d_wide$i5)

# u = i8
summary(d_wide$u - d_wide$i8)
```

-   The reconstructed values which can be checked against values from
    the simulation are correct except for approximation error due to the
    low precision of the numbers in the files.

# Distribution summary

Display a quick summary of the distributions of values of all the nodes.

Note that these summaries are over all the input files pooled.

```{r}
skimr::skim(d_wide)
```

# Plots

Plot the relationships between the major nodes. This is not necessarily
of immediate use in deciding the design fo VSA components, but gives a
feel for the dynamics of the system.

## Time explicit

Show the values of the major nodes as a function of time.

```{r}
p <- d_wide %>% 
  dplyr::mutate(
    k_start = k_start %>% forcats::as_factor(),
    d2z = dz - lag(dz, n = 1, default = NA) # get vertical acceleration
  ) %>% 
  ggplot(aes(x = t, group = k_start, colour = k_start))

p + geom_path(aes(y = z))
p + geom_path(aes(y = dz))
p + geom_path(aes(y = d2z))
p + geom_path(aes(y = e))
p + geom_path(aes(y = ei))
p + geom_path(aes(y = u))
```

## Time implicit

Show the values of the major nodes as a function of each other (with
time implicit).

```{r}
p <- d_wide %>% 
  dplyr::mutate(
    k_start = k_start %>% forcats::as_factor(),
    d2z = dz - lag(dz, n = 1, default = NA) # get vertical acceleration
  ) %>% 
  ggplot(aes(group = k_start, colour = k_start))

p + geom_path(aes(x = z, y = dz))
p + geom_path(aes(x = z, y = d2z))
p + geom_path(aes(x = z, y = e))
p + geom_path(aes(x = z, y = ei))
p + geom_path(aes(x = z, y = u))

p + geom_path(aes(x = dz, y = d2z))
p + geom_path(aes(x = dz, y = e))
p + geom_path(aes(x = dz, y = ei))
p + geom_path(aes(x = dz, y = u))

p + geom_path(aes(x = d2z, y = e))
p + geom_path(aes(x = d2z, y = ei))
p + geom_path(aes(x = d2z, y = u))

p + geom_path(aes(x = e, y = ei))
p + geom_path(aes(x = e, y = u))

p + geom_path(aes(x = ei, y = u))
```
